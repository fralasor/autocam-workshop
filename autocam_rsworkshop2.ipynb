{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "from shapely import geometry\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "ee.Authenticate()\n",
    "# ee.Initialize()\n",
    "ee.Initialize(project=\"ee-fasoriano\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the area of interest (AOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to the GeoJSON file on GitHub\n",
    "geojson_url = 'https://raw.githubusercontent.com/fralasor/autocam-workshop/main/rsws_region_bboxes.geojson'\n",
    "\n",
    "# Fetch the GeoJSON file\n",
    "geojson_data = requests.get(geojson_url).json()\n",
    "\n",
    "# Create a map instance\n",
    "map1 = geemap.Map()\n",
    "\n",
    "# Load GeoJSON into a GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame.from_features(geojson_data['features'])\n",
    "# display(gdf)\n",
    "\n",
    "# Select the AOI based on its ID\n",
    "# Bago City for this workshop\n",
    "feature = gdf[gdf['id'] == 0].squeeze()\n",
    "\n",
    "# Convert the selected feature geometry to a Shapely object\n",
    "geom = feature.geometry\n",
    "\n",
    "# Convert Shapely geometry to GeoJSON\n",
    "geom_geojson = geometry.mapping(geom)\n",
    "aoi_bbox = ee.FeatureCollection(ee.Geometry(geom_geojson))\n",
    "\n",
    "# AOI Visualization\n",
    "aoi_style = {\n",
    "    'color': 'red', \n",
    "    'width': 2,\n",
    "    'lineType': 'solid',\n",
    "    'fillColor': '00000000',\n",
    "}\n",
    "\n",
    "# Add the selected AOI to the map\n",
    "map1.addLayer(aoi_bbox.style(**aoi_style), {}, \"Selected AOI\")\n",
    "map1.centerObject(aoi_bbox)\n",
    "\n",
    "# Display the map\n",
    "map1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You can also use the two following lines to set your AOI based on a shp/json file  \n",
    "# extent_path = fr\"D:/fsori/Documents/AUTOCAM/Study Area/tagum_boundbox.geojson\"\n",
    "# AOI = geemap.geojson_to_ee(extent_path)\n",
    "\"\"\"\n",
    "\n",
    "AOI = aoi_bbox\n",
    "START_DATE = '2023-01-01'\n",
    "END_DATE = '2023-03-31'\n",
    "CLOUD_FILTER = 60\n",
    "CLD_PRB_THRESH = 40\n",
    "NIR_DRK_THRESH = 0.15\n",
    "CLD_PRJ_DIST_km = 2\n",
    "BUFFER_m = 100\n",
    "output_name = 'bago_2023_q1_s2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloud masking using S2 cloud probability dataset (s2cloudless) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions for cloud-masking\n",
    "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
    "    # Import and filter S2 SR.\n",
    "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
    "\n",
    "    # Import and filter s2cloudless.\n",
    "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
    "        .filterBounds(aoi)\n",
    "        .filterDate(start_date, end_date))\n",
    "\n",
    "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
    "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
    "        'primary': s2_sr_col,\n",
    "        'secondary': s2_cloudless_col,\n",
    "        'condition': ee.Filter.equals(**{\n",
    "            'leftField': 'system:index',\n",
    "            'rightField': 'system:index'\n",
    "        })\n",
    "    }))\n",
    "    \n",
    "def add_cloud_bands(img):\n",
    "    # Get s2cloudless image, subset the probability band.\n",
    "    cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
    "\n",
    "    # Condition s2cloudless by the probability threshold value.\n",
    "    is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
    "\n",
    "    # Add the cloud probability layer and cloud mask as image bands.\n",
    "    return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
    "\n",
    "def add_shadow_bands(img):\n",
    "    # Identify water pixels from the SCL band.\n",
    "    not_water = img.select('SCL').neq(6)\n",
    "\n",
    "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
    "    SR_BAND_SCALE = 1e4\n",
    "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
    "\n",
    "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
    "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
    "\n",
    "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST_km input.\n",
    "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST_km*10)\n",
    "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
    "        .select('distance')\n",
    "        .mask()\n",
    "        .rename('cloud_transform'))\n",
    "\n",
    "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
    "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
    "\n",
    "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
    "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
    "\n",
    "def add_cld_shdw_mask(img):\n",
    "    # Add cloud component bands.\n",
    "    img_cloud = add_cloud_bands(img)\n",
    "\n",
    "    # Add cloud shadow component bands.\n",
    "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
    "\n",
    "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
    "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
    "\n",
    "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
    "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
    "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER_m*2/20)\n",
    "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
    "        .rename('cloudmask'))\n",
    "\n",
    "    # Add the final cloud-shadow mask to the image.\n",
    "    return img_cloud_shadow.addBands(is_cld_shdw)\n",
    "\n",
    "def apply_cld_shdw_mask(img):\n",
    "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
    "    not_cld_shdw = img.select('cloudmask').Not()\n",
    "\n",
    "    # Subset reflectance bands and update their masks, return the result.\n",
    "    return img.select('B.*').updateMask(not_cld_shdw)\n",
    "\n",
    "# Sentinel 2 Visualization\n",
    "s2_visualization = {\n",
    "    'min': 0,\n",
    "    'max': 10000,\n",
    "    'bands': ['B4', 'B3', 'B2'],\n",
    "    'gamma': 1.2\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling S2 image collection & Adding cloud-free composites to basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Sentinel 2 image collection within the set time period\n",
    "s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "        .filterBounds(AOI)\n",
    "        .filterDate(START_DATE, END_DATE)\n",
    "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER))\n",
    "        )\n",
    "\n",
    "# APPLYING S2 CLOUD MASK\n",
    "s2_sr_cld_col = get_s2_sr_cld_col(AOI, START_DATE, END_DATE)\n",
    "s2_sr_median = (s2_sr_cld_col.map(add_cld_shdw_mask)\n",
    "                             .map(apply_cld_shdw_mask)\n",
    "                             .median())\n",
    "\n",
    "# Add median cloud-free composite\n",
    "map1.addLayer(s2_sr_median.clip(aoi_bbox), s2_visualization, name='s2 median cloudless')\n",
    "\n",
    "# Bring AOI polygon to top\n",
    "map1.remove(aoi_bbox)\n",
    "map1.addLayer(aoi_bbox.style(**aoi_style), {}, \"Selected AOI\")\n",
    "\n",
    "# Display map\n",
    "map1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All band names:', s2_sr_median.bandNames().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading training and testing data\n",
    "\n",
    "Setting visualization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"https://raw.githubusercontent.com/fralasor/autocam-workshop/main/bago_train_2023.geojson\"\n",
    "test_data_path = \"https://raw.githubusercontent.com/fralasor/autocam-workshop/main/bago_test_2023.geojson\"\n",
    "\n",
    "# Fetch the GeoJSON file\n",
    "train_data = requests.get(train_data_path).json()\n",
    "test_data = requests.get(test_data_path).json()\n",
    "\n",
    "lc_labels_dict = {\n",
    "    1:\"inland water\",\n",
    "    2:\"grassland\",\n",
    "    3:\"fallow land\",\n",
    "    4:\"crops\",\n",
    "    5:\"coastal water\",\n",
    "    6:\"built-up\",\n",
    "    7:\"barren\",\n",
    "    8:\"trees\",\n",
    "    9:\"brush\",\n",
    "    10:\"fishpond\",\n",
    "    11:\"mangrove\"\n",
    "    }\n",
    "\n",
    "lc_colors = [\n",
    "    '#1f77b4',  # inland water\n",
    "    '#2ca02c',  # grassland\n",
    "    '#ff7f0e',  # fallow land\n",
    "    '#d62728',  # crops\n",
    "    '#17becf',  # coastal water\n",
    "    '#9467bd',  # built-up\n",
    "    '#8c564b',  # barren\n",
    "    '#e377c2',  # trees\n",
    "    '#7f7f7f',  # brush\n",
    "    '#bcbd22',  # fishpond\n",
    "    '#ffbb78'   # mangrove\n",
    "]\n",
    "\n",
    "rf_vis_param = {'min': 1, 'max': 11, 'palette': lc_colors}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing and Training Supervised Classification Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = s2_sr_median.bandNames().getInfo()\n",
    "label = \"lc_code\"\n",
    "\n",
    "training = s2_sr_median.select(bands).sampleRegions(**{\n",
    "    'collection':train_data,\n",
    "    'properties':[label],\n",
    "    'scale':10,\n",
    "})\n",
    "\n",
    "classifier = ee.Classifier.smileRandomForest(100).train(training, label, bands) # .train()\n",
    "\n",
    "result = s2_sr_median.select(bands).classify(classifier) #.classify() 'trained' => trained classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Land Cover Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1.addLayer(result.clip(AOI), rf_vis_param, 'classified')\n",
    "map1.add_legend(title=\"Land Cover\", labels=list(lc_labels_dict.values()), colors=lc_colors)\n",
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "\n",
    "validation = s2_sr_median.select(bands).sampleRegions(**{\n",
    "    'collection':test_data,\n",
    "    'properties':[label],\n",
    "    'scale':10,\n",
    "})\n",
    "\n",
    "test = validation.classify(classifier)\n",
    "\n",
    "confusionMatrix = test.errorMatrix('lc_code','classification')\n",
    "\n",
    "# print('RF Consumer\\'s accuracy (Omission)', confusionMatrix.consumersAccuracy().getInfo())\n",
    "# print('RF Producer\\'s accuracy (Commission)', confusionMatrix.producersAccuracy().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RF Overall accuracy', confusionMatrix.accuracy().getInfo())\n",
    "print('RF Kappa Coefficient', confusionMatrix.kappa().getInfo())\n",
    "\n",
    "# Create dataframe for confusion matrix\n",
    "conf_df = pd.DataFrame(confusionMatrix.getInfo())\n",
    "conf_df.drop(0, axis=1, inplace=True)\n",
    "conf_df.drop(0, axis=0, inplace=True)\n",
    "\n",
    "# Display confusion matrix\n",
    "conf_df.columns = list(lc_labels_dict.values())\n",
    "conf_df['index'] = list(lc_labels_dict.values())\n",
    "conf_df.set_index('index', inplace=True)\n",
    "display(conf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting land cover map to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = ee.batch.Export.image.toDrive(**{\n",
    "    'image': result.clip(aoi_bbox),\n",
    "    'description': output_name+'_classified',\n",
    "    'folder': 'autocam_s2',\n",
    "    'scale': 10,\n",
    "    'region': aoi_bbox.geometry(),\n",
    "    'crs': 'EPSG:4326'\n",
    "    \n",
    "})\n",
    "\n",
    "task.start()\n",
    "print(f\"Running task {task.status()['task_type']} of {task.status()['description']}\")\n",
    "\n",
    "while(task.status()['state'] != 'COMPLETED'):\n",
    "    continue\n",
    "\n",
    "task.status()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global Human Settlement Layer (GHSL) Building Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2 = geemap.Map()\n",
    "map2.add_basemap('SATELLITE')\n",
    "\n",
    "ghsl = ee.ImageCollection(\"JRC/GHSL/P2023A/GHS_BUILT_C\").select('built_characteristics')\n",
    "ghsl_class_table = \"\"\"\n",
    "Value\tColor\tDescription\n",
    "1\t#718c6c\topen spaces, low vegetation surfaces\n",
    "2\t#8ad86b\topen spaces, medium vegetation surfaces\n",
    "3\t#c1ffa1\topen spaces, high vegetation surfaces\n",
    "4\t#01b7ff\topen spaces, water surfaces\n",
    "5\t#ffd501\topen spaces, road surfaces\n",
    "11\t#d28200\tbuilt spaces, residential, building height <= 3m\n",
    "12\t#fe5900\tbuilt spaces, residential, 3m < building height <= 6m\n",
    "13\t#ff0101\tbuilt spaces, residential, 6m < building height <= 15m\n",
    "14\t#ce001b\tbuilt spaces, residential, 15m < building height <= 30m\n",
    "15\t#7a000a\tbuilt spaces, residential, building height > 30m\n",
    "21\t#ff9ff4\tbuilt spaces, non-residential, building height <= 3m\n",
    "22\t#ff67e4\tbuilt spaces, non-residential, 3m < building height <= 6m\n",
    "23\t#f701ff\tbuilt spaces, non-residential, 6m < building height <= 15m\n",
    "24\t#a601ff\tbuilt spaces, non-residential, 15m < building height <= 30m\n",
    "25\t#6e00fe\tbuilt spaces, non-residential, building height > 30m\n",
    "\"\"\"\n",
    "\n",
    "ghsl_class_table_df = pd.read_csv(StringIO(ghsl_class_table), sep=\"\\t\")\n",
    "display(ghsl_class_table_df)\n",
    "\n",
    "ghsl_vis_param = {'min': 1, 'max': 25, 'palette': list(ghsl_class_table_df['Color'])}\n",
    "\n",
    "legend_dict = geemap.legend_from_ee(ghsl_class_table)\n",
    "map2.add_legend(title=\"GHSL 2018\", legend_dict=legend_dict)\n",
    "map2.addLayer(ghsl, ghsl_vis_param, 'GHSL')\n",
    "# Add the selected AOI to the map\n",
    "map2.addLayer(aoi_bbox.style(**aoi_style), {}, \"Selected AOI\")\n",
    "map2.centerObject(aoi_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic World Land Cover dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a collection of corresponding Dynamic World and Sentinel-2 for\n",
    "# inspection. Filter the DW and S2 collections by region and date.\n",
    "START = ee.Date('2023-03-01')\n",
    "END = START.advance(30, 'day')\n",
    "\n",
    "col_filter = ee.Filter.And(\n",
    "    ee.Filter.bounds(AOI),\n",
    "    ee.Filter.date(START, END),\n",
    ")\n",
    "\n",
    "dw_col = ee.ImageCollection('GOOGLE/DYNAMICWORLD/V1').filter(col_filter)\n",
    "s2_col = ee.ImageCollection('COPERNICUS/S2_HARMONIZED').filter(col_filter)\n",
    "\n",
    "# Join corresponding DW and S2 images (by system:index).\n",
    "dw_s2_col = ee.Join.saveFirst('s2_img').apply(\n",
    "    dw_col,\n",
    "    s2_col,\n",
    "    ee.Filter.equals(leftField='system:index', rightField='system:index'),\n",
    ")\n",
    "\n",
    "# Extract an example DW image and its source S2 image.\n",
    "dw_image = ee.Image(dw_s2_col.first())\n",
    "s2_image = ee.Image(dw_image.get('s2_img'))\n",
    "\n",
    "# Create a visualization that blends DW class label with probability.\n",
    "# Define list pairs of DW LULC label and color.\n",
    "CLASS_NAMES = [\n",
    "    'water',\n",
    "    'trees',\n",
    "    'grass',\n",
    "    'flooded_vegetation',\n",
    "    'crops',\n",
    "    'shrub_and_scrub',\n",
    "    'built',\n",
    "    'bare',\n",
    "    'snow_and_ice',\n",
    "]\n",
    "\n",
    "VIS_PALETTE = [\n",
    "    '419bdf',\n",
    "    '397d49',\n",
    "    '88b053',\n",
    "    '7a87c6',\n",
    "    'e49635',\n",
    "    'dfc35a',\n",
    "    'c4281b',\n",
    "    'a59b8f',\n",
    "    'b39fe1',\n",
    "]\n",
    "\n",
    "# Create an RGB image of the label (most likely class) on [0, 1].\n",
    "dw_rgb = (\n",
    "    dw_image.select('label')\n",
    "    .visualize(min=0, max=8, palette=VIS_PALETTE)\n",
    "    .divide(255)\n",
    ")\n",
    "\n",
    "# Get the most likely class probability.\n",
    "top1_prob = dw_image.select(CLASS_NAMES).reduce(ee.Reducer.max())\n",
    "\n",
    "# Create a hillshade of the most likely class probability on [0, 1]\n",
    "top1_prob_hillshade = ee.Terrain.hillshade(top1_prob.multiply(100)).divide(255)\n",
    "\n",
    "# Combine the RGB image with the hillshade.\n",
    "dw_rgb_hillshade = dw_rgb.multiply(top1_prob_hillshade)\n",
    "\n",
    "# Display the Dynamic World visualization with the source Sentinel-2 image.\n",
    "map3 = geemap.Map()\n",
    "map3.centerObject(AOI)\n",
    "map3.add_layer(\n",
    "    s2_image,\n",
    "    {'min': 0, 'max': 3000, 'bands': ['B4', 'B3', 'B2']},\n",
    "    'Sentinel-2 L1C',\n",
    ")\n",
    "map3.add_layer(\n",
    "    dw_rgb_hillshade,\n",
    "    {'min': 0, 'max': 0.65},\n",
    "    'Dynamic World V1 - label hillshade',\n",
    ")\n",
    "map3.add_legend(title=\"Dynamic World LC\", labels=CLASS_NAMES, colors=VIS_PALETTE)\n",
    "map3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lupa_02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
